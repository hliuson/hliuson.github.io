+++
title = 'About'
date = 2024-10-06T11:34:16-04:00
menu = "main"
weight = 50
+++
# About Me
I am a 4th year student at the University of Rochester, majoring in Computer Science and History with a minor in Mathematics. I am currently working with Jianxun Lian at Microsoft Research Asia on adapting LLMs for roleplay tasks, which you can read about here: [Low-Parameter Soft-Prompt Learning for Behavioral Adaptation in LLMs](/posts/low-param-soft-prompt/).

At the University of Rochester I have had the privilege of working with Professors Lane Hemaspaandra, Chris Kanan, and PhD students Michael C. Chavrimootoo (Now professor) and Jhair Gallardo.

I published two critique papers on arXiv which debunked preprints which claimed to resolve the P=NP question.
 - [Evaluating the Claims of "SAT Requires Exhaustive Search"](/posts/xu-zhou-critique)
 - [A Critique of Du's "A Polynomial-Time Algorithm for 3-SAT"](/posts/du-3sat-critique)


### Interests
Some examples of work that interests me include (but are not limited to):
- Mathematical reasoning in LLMs using an external source-of-truth, the Lean compiler ([AlphaProof](https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/) and [DeepSeek-Prover-V1.5](https://arxiv.org/pdf/2408.08152)). I believe that incorporating these kinds of verifiers and sources of truth will be important both assessing reward when performing RL fine-tuning on LLMs but also when curating datasets for supervised fine-tuning.
- Employing LLMs to perform search at a scale impractical or uneconomical for humans, allowing the optimization of reward functions for RL ([Eureka](https://arxiv.org/abs/2310.12931)) or discrete skills in Minecraft ([Voyager](https://arxiv.org/abs/2305.16291)). This kind of LLM-guided search has the additional benefit of allowing humans to specify more nuanced objectives in text which can be better aligned than blindly optimizing a reward which may be misaligned with desired behavior or difficult to specify exactly.
 - Automated methods to understand and intervene on the internal behavior of models, such as by disentangling superimposed feature vectors using autoencoders ([Scaling Monosemanticity](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)) or by extracting a high-level action space from a pre-trained reinforcement learning policy ([Adverserial Skill Embeddings](https://arxiv.org/pdf/2205.01906)).


### Misc    
 Outside of computer science, I am interested in history with a focus on political economy and imperialism. You can find some of my writings which discuss the role of particular local elites in imperialism here:
 - [Feudalism and Class Power in Rural Manchukuo](/posts/feudalism-manchukuo)
 - [Elite Convergence in the Colonial Andes](/posts/colonial-andes)